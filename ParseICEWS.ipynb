{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose is to create directories with the data that can be used for S,D,MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will use GDELT template\n",
    "# external libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "# internal libraries\n",
    "import PullData as pldta\n",
    "import DataAggregation as da\n",
    "import CreateGraphs as cg\n",
    "import CreateNodeEmbeddings as cne\n",
    "import CreateFeatures as cf\n",
    "import TrainTest as tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "year_range = range(1995,2017)\n",
    "month_range = range(1,13)\n",
    "\n",
    "num_time_steps = 0\n",
    "year_dict = {}\n",
    "\n",
    "for year in year_range:\n",
    "    for month in month_range:\n",
    "        year_dict[num_time_steps]=year\n",
    "        num_time_steps += 1\n",
    "print(num_time_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded: 1995 (151310, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (131008, 10)\n",
      "after dropna (131008, 10)\n",
      "(131008, 10)\n",
      "249\n",
      "downloaded: 1996 (235269, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (201703, 10)\n",
      "after dropna (201703, 10)\n",
      "(201703, 10)\n",
      "255\n",
      "downloaded: 1997 (251425, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (216843, 10)\n",
      "after dropna (216843, 10)\n",
      "(216843, 10)\n",
      "259\n",
      "downloaded: 1998 (368318, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (310790, 10)\n",
      "after dropna (310790, 10)\n",
      "(310790, 10)\n",
      "261\n",
      "downloaded: 1999 (545102, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (446734, 10)\n",
      "after dropna (446734, 10)\n",
      "(446734, 10)\n",
      "271\n",
      "downloaded: 2000 (654613, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (520772, 10)\n",
      "after dropna (520772, 10)\n",
      "(520772, 10)\n",
      "279\n",
      "downloaded: 2001 (797924, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (604423, 10)\n",
      "after dropna (604423, 10)\n",
      "(604423, 10)\n",
      "291\n",
      "downloaded: 2002 (825060, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (628298, 10)\n",
      "after dropna (628298, 10)\n",
      "(628298, 10)\n",
      "288\n",
      "downloaded: 2003 (850489, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (640040, 10)\n",
      "after dropna (640040, 10)\n",
      "(640040, 10)\n",
      "290\n",
      "downloaded: 2004 (953820, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (718671, 10)\n",
      "after dropna (718671, 10)\n",
      "(718671, 10)\n",
      "295\n",
      "downloaded: 2005 (1013400, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (760389, 10)\n",
      "after dropna (760389, 10)\n",
      "(760389, 10)\n",
      "304\n",
      "downloaded: 2006 (1118996, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (816826, 10)\n",
      "after dropna (816826, 10)\n",
      "(816826, 10)\n",
      "299\n",
      "downloaded: 2007 (1011161, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (755798, 10)\n",
      "after dropna (755798, 10)\n",
      "(755798, 10)\n",
      "293\n",
      "downloaded: 2008 (980879, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (744652, 10)\n",
      "after dropna (744652, 10)\n",
      "(744652, 10)\n",
      "300\n",
      "downloaded: 2009 (857511, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (667111, 10)\n",
      "after dropna (667111, 10)\n",
      "(667111, 10)\n",
      "286\n",
      "downloaded: 2010 (722523, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (577537, 10)\n",
      "after dropna (577537, 10)\n",
      "(577537, 10)\n",
      "285\n",
      "downloaded: 2011 (636322, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (511581, 10)\n",
      "after dropna (511581, 10)\n",
      "(511581, 10)\n",
      "279\n",
      "downloaded: 2012 (683523, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (555499, 10)\n",
      "after dropna (555499, 10)\n",
      "(555499, 10)\n",
      "283\n",
      "downloaded: 2013 (734989, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (589474, 10)\n",
      "after dropna (589474, 10)\n",
      "(589474, 10)\n",
      "282\n",
      "downloaded: 2014 (879393, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (698973, 10)\n",
      "after dropna (698973, 10)\n",
      "(698973, 10)\n",
      "276\n",
      "downloaded: 2015 (955349, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (731337, 10)\n",
      "after dropna (731337, 10)\n",
      "(731337, 10)\n",
      "286\n",
      "downloaded: 2016 (787612, 20)\n",
      "date parsed\n",
      "agents cleaned\n",
      "columns dropped\n",
      "before dropna (600449, 10)\n",
      "after dropna (600449, 10)\n",
      "(600449, 10)\n",
      "278\n"
     ]
    }
   ],
   "source": [
    "# dict of dfs\n",
    "importlib.reload(pldta)\n",
    "year_df_dict = pldta.GetDfDictByYear(year_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pldta)\n",
    "country_predict_list,country_region_dict,region_country_set_dict = pldta.GetCountryData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pldta)\n",
    "nmc_dict=pldta.GetNMC(year_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Violence Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Latin America & Caribbean', 'Sub-Saharan Africa', 'North America', 'East Asia & Pacific', 'South Asia', 'Europe & Central Asia', 'Middle East & North Africa']\n",
      "1995 -115600.9\n",
      "1996 -154798.2\n",
      "1997 -154466.4\n",
      "1998 -198164.3\n",
      "1999 -314337.6\n",
      "2000 -348016.69999999995\n",
      "2001 -443193.0\n",
      "2002 -415621.1\n",
      "2003 -423400.89999999997\n",
      "2004 -615199.8\n",
      "2005 -593916.3\n",
      "2006 -696772.3999999999\n",
      "2007 -632468.7\n",
      "2008 -655376.5000000001\n",
      "2009 -596213.4\n",
      "2010 -528130.5\n",
      "2011 -553619.0\n",
      "2012 -569978.1\n",
      "2013 -583401.4000000001\n",
      "2014 -748147.6\n",
      "2015 -783763.5\n",
      "2016 -622450.2000000001\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pldta)\n",
    "# by region\n",
    "region_violence_dict = pldta.GetViolQuadDataRegion(year_df_dict,country_region_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995 -115600.9\n",
      "1996 -154798.2\n",
      "1997 -154466.4\n",
      "1998 -198164.3\n",
      "1999 -314337.6\n",
      "2000 -348016.69999999995\n",
      "2001 -443193.0\n",
      "2002 -415621.1\n",
      "2003 -423400.89999999997\n",
      "2004 -615199.8\n",
      "2005 -593916.3\n",
      "2006 -696772.3999999999\n",
      "2007 -632468.7\n",
      "2008 -655376.5000000001\n",
      "2009 -596213.4\n",
      "2010 -528130.5\n",
      "2011 -553619.0\n",
      "2012 -569978.1\n",
      "2013 -583401.4000000001\n",
      "2014 -748147.6\n",
      "2015 -783763.5\n",
      "2016 -622450.2000000001\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pldta)\n",
    "# by country\n",
    "country_violence_dict = pldta.GetViolQuadDataCountry(year_df_dict,country_predict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for region,year_data in region_violence_dict.items():\n",
    "    print(region)\n",
    "    vec = np.zeros(num_time_steps)\n",
    "    idx = 0\n",
    "    for year,month_data in year_data.items():\n",
    "        for month,lev in month_data.items():\n",
    "            vec[idx] = lev\n",
    "            idx+=1\n",
    "    plt.plot(vec)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(pldta)\n",
    "country_class_labels_dict,chaos_dict = pldta.GetClassVec(country_violence_dict,num_time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pldta)\n",
    "region_class_labels_dict,region_dict = pldta.GetClassVec(region_violence_dict,num_time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Latin America & Caribbean': None,\n",
       " 'Sub-Saharan Africa': None,\n",
       " 'North America': None,\n",
       " 'East Asia & Pacific': None,\n",
       " 'South Asia': None,\n",
       " 'Europe & Central Asia': None,\n",
       " 'Middle East & North Africa': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for country,labels in country_class_labels_dict.items():\n",
    "    c=0\n",
    "    num=0\n",
    "    cat_list = ['first ','second','third ','fourth']\n",
    "    for i,label_1 in enumerate(labels):\n",
    "        if i < 49:\n",
    "            continue\n",
    "        vec = np.array([(np.array(labels[:i])==cat).sum() for cat in cat_list])\n",
    "        if label_1==cat_list[vec.argmax()]:\n",
    "            c+=1\n",
    "        num+=1\n",
    "    print(country + \"::\" + str(c) + \"::\" + str(num))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for region,ts in region_class_labels_dict.items():\n",
    "    print(region)\n",
    "    num=0\n",
    "    c=0\n",
    "    for idx,tok in enumerate(ts[:-1]):\n",
    "        if idx < 36:\n",
    "            continue\n",
    "        if ts[idx]==ts[idx+1]:\n",
    "            c+=1\n",
    "        num+=1\n",
    "        \n",
    "    print(c/num,num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importlib.reload(da)\n",
    "indicator_year_month_dict = da.AggregateWGIData(year_range,country_predict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "importlib.reload(cg)\n",
    "import os\n",
    "country_done_list = [country for country in os.listdir(\"CountryGraphData\")]\n",
    "country_done_list.remove('.ipynb_checkpoints')\n",
    "country_done_list.sort()\n",
    "\n",
    "for country in country_done_list:\n",
    "    if country in country_predict_list:\n",
    "        country_predict_list.remove(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year: 1995 month 1\n",
      "year: 1995 month 2\n",
      "year: 1995 month 3\n",
      "year: 1995 month 4\n",
      "year: 1995 month 5\n",
      "year: 1995 month 6\n",
      "year: 1995 month 7\n",
      "year: 1995 month 8\n",
      "year: 1995 month 9\n",
      "year: 1995 month 10\n",
      "year: 1995 month 11\n",
      "year: 1995 month 12\n",
      "year: 1996 month 1\n",
      "year: 1996 month 2\n",
      "year: 1996 month 3\n",
      "year: 1996 month 4\n",
      "year: 1996 month 5\n",
      "year: 1996 month 6\n",
      "year: 1996 month 7\n",
      "year: 1996 month 8\n",
      "year: 1996 month 9\n",
      "year: 1996 month 10\n",
      "year: 1996 month 11\n",
      "year: 1996 month 12\n",
      "year: 1997 month 1\n",
      "year: 1997 month 2\n",
      "year: 1997 month 3\n",
      "year: 1997 month 4\n",
      "year: 1997 month 5\n",
      "year: 1997 month 6\n",
      "year: 1997 month 7\n",
      "year: 1997 month 8\n",
      "year: 1997 month 9\n",
      "year: 1997 month 10\n",
      "year: 1997 month 11\n",
      "year: 1997 month 12\n",
      "year: 1998 month 1\n",
      "year: 1998 month 2\n",
      "year: 1998 month 3\n",
      "year: 1998 month 4\n",
      "year: 1998 month 5\n",
      "year: 1998 month 6\n",
      "year: 1998 month 7\n",
      "year: 1998 month 8\n",
      "year: 1998 month 9\n",
      "year: 1998 month 10\n",
      "year: 1998 month 11\n",
      "year: 1998 month 12\n",
      "year: 1999 month 1\n",
      "year: 1999 month 2\n",
      "year: 1999 month 3\n",
      "year: 1999 month 4\n",
      "year: 1999 month 5\n",
      "year: 1999 month 6\n",
      "year: 1999 month 7\n",
      "year: 1999 month 8\n",
      "year: 1999 month 9\n",
      "year: 1999 month 10\n",
      "year: 1999 month 11\n",
      "year: 1999 month 12\n",
      "year: 2000 month 1\n",
      "year: 2000 month 2\n",
      "year: 2000 month 3\n",
      "year: 2000 month 4\n",
      "year: 2000 month 5\n",
      "year: 2000 month 6\n",
      "year: 2000 month 7\n",
      "year: 2000 month 8\n",
      "year: 2000 month 9\n",
      "year: 2000 month 10\n",
      "year: 2000 month 11\n",
      "year: 2000 month 12\n",
      "year: 2001 month 1\n",
      "year: 2001 month 2\n",
      "year: 2001 month 3\n",
      "year: 2001 month 4\n",
      "year: 2001 month 5\n",
      "year: 2001 month 6\n",
      "year: 2001 month 7\n",
      "year: 2001 month 8\n",
      "year: 2001 month 9\n",
      "year: 2001 month 10\n",
      "year: 2001 month 11\n",
      "year: 2001 month 12\n",
      "year: 2002 month 1\n",
      "year: 2002 month 2\n",
      "year: 2002 month 3\n",
      "year: 2002 month 4\n",
      "year: 2002 month 5\n",
      "year: 2002 month 6\n",
      "year: 2002 month 7\n",
      "year: 2002 month 8\n",
      "year: 2002 month 9\n",
      "year: 2002 month 10\n",
      "year: 2002 month 11\n",
      "year: 2002 month 12\n",
      "year: 2003 month 1\n",
      "year: 2003 month 2\n",
      "year: 2003 month 3\n",
      "year: 2003 month 4\n",
      "year: 2003 month 5\n",
      "year: 2003 month 6\n",
      "year: 2003 month 7\n",
      "year: 2003 month 8\n",
      "year: 2003 month 9\n",
      "year: 2003 month 10\n",
      "year: 2003 month 11\n",
      "year: 2003 month 12\n",
      "year: 2004 month 1\n",
      "year: 2004 month 2\n",
      "year: 2004 month 3\n",
      "year: 2004 month 4\n",
      "year: 2004 month 5\n",
      "year: 2004 month 6\n",
      "year: 2004 month 7\n",
      "year: 2004 month 8\n",
      "year: 2004 month 9\n",
      "year: 2004 month 10\n",
      "year: 2004 month 11\n",
      "year: 2004 month 12\n",
      "year: 2005 month 1\n",
      "year: 2005 month 2\n",
      "year: 2005 month 3\n",
      "year: 2005 month 4\n",
      "year: 2005 month 5\n",
      "year: 2005 month 6\n",
      "year: 2005 month 7\n",
      "year: 2005 month 8\n",
      "year: 2005 month 9\n",
      "year: 2005 month 10\n",
      "year: 2005 month 11\n",
      "year: 2005 month 12\n",
      "year: 2006 month 1\n",
      "year: 2006 month 2\n",
      "year: 2006 month 3\n",
      "year: 2006 month 4\n",
      "year: 2006 month 5\n",
      "year: 2006 month 6\n",
      "year: 2006 month 7\n",
      "year: 2006 month 8\n",
      "year: 2006 month 9\n",
      "year: 2006 month 10\n",
      "year: 2006 month 11\n",
      "year: 2006 month 12\n",
      "year: 2007 month 1\n",
      "year: 2007 month 2\n",
      "year: 2007 month 3\n",
      "year: 2007 month 4\n",
      "year: 2007 month 5\n",
      "year: 2007 month 6\n",
      "year: 2007 month 7\n",
      "year: 2007 month 8\n",
      "year: 2007 month 9\n",
      "year: 2007 month 10\n",
      "year: 2007 month 11\n",
      "year: 2007 month 12\n",
      "year: 2008 month 1\n",
      "year: 2008 month 2\n",
      "year: 2008 month 3\n",
      "year: 2008 month 4\n",
      "year: 2008 month 5\n",
      "year: 2008 month 6\n",
      "year: 2008 month 7\n",
      "year: 2008 month 8\n",
      "year: 2008 month 9\n",
      "year: 2008 month 10\n",
      "year: 2008 month 11\n",
      "year: 2008 month 12\n",
      "year: 2009 month 1\n",
      "year: 2009 month 2\n",
      "year: 2009 month 3\n",
      "year: 2009 month 4\n",
      "year: 2009 month 5\n",
      "year: 2009 month 6\n",
      "year: 2009 month 7\n",
      "year: 2009 month 8\n",
      "year: 2009 month 9\n",
      "year: 2009 month 10\n",
      "year: 2009 month 11\n",
      "year: 2009 month 12\n",
      "year: 2010 month 1\n",
      "year: 2010 month 2\n",
      "year: 2010 month 3\n",
      "year: 2010 month 4\n",
      "year: 2010 month 5\n",
      "year: 2010 month 6\n",
      "year: 2010 month 7\n",
      "year: 2010 month 8\n",
      "year: 2010 month 9\n",
      "year: 2010 month 10\n",
      "year: 2010 month 11\n",
      "year: 2010 month 12\n",
      "year: 2011 month 1\n",
      "year: 2011 month 2\n",
      "year: 2011 month 3\n",
      "year: 2011 month 4\n",
      "year: 2011 month 5\n",
      "year: 2011 month 6\n",
      "year: 2011 month 7\n",
      "year: 2011 month 8\n",
      "year: 2011 month 9\n",
      "year: 2011 month 10\n",
      "year: 2011 month 11\n",
      "year: 2011 month 12\n",
      "year: 2012 month 1\n",
      "year: 2012 month 2\n",
      "year: 2012 month 3\n",
      "year: 2012 month 4\n",
      "year: 2012 month 5\n",
      "year: 2012 month 6\n",
      "year: 2012 month 7\n",
      "year: 2012 month 8\n",
      "year: 2012 month 9\n",
      "year: 2012 month 10\n",
      "year: 2012 month 11\n",
      "year: 2012 month 12\n",
      "year: 2013 month 1\n",
      "year: 2013 month 2\n",
      "year: 2013 month 3\n",
      "year: 2013 month 4\n",
      "year: 2013 month 5\n",
      "year: 2013 month 6\n",
      "year: 2013 month 7\n",
      "year: 2013 month 8\n",
      "year: 2013 month 9\n",
      "year: 2013 month 10\n",
      "year: 2013 month 11\n",
      "year: 2013 month 12\n",
      "year: 2014 month 1\n",
      "year: 2014 month 2\n",
      "year: 2014 month 3\n",
      "year: 2014 month 4\n",
      "year: 2014 month 5\n",
      "year: 2014 month 6\n",
      "year: 2014 month 7\n",
      "year: 2014 month 8\n",
      "year: 2014 month 9\n",
      "year: 2014 month 10\n",
      "year: 2014 month 11\n",
      "year: 2014 month 12\n",
      "year: 2015 month 1\n",
      "year: 2015 month 2\n",
      "year: 2015 month 3\n",
      "year: 2015 month 4\n",
      "year: 2015 month 5\n",
      "year: 2015 month 6\n",
      "year: 2015 month 7\n",
      "year: 2015 month 8\n",
      "year: 2015 month 9\n",
      "year: 2015 month 10\n",
      "year: 2015 month 11\n",
      "year: 2015 month 12\n",
      "year: 2016 month 1\n",
      "year: 2016 month 2\n",
      "year: 2016 month 3\n",
      "year: 2016 month 4\n",
      "year: 2016 month 5\n",
      "year: 2016 month 6\n",
      "year: 2016 month 7\n",
      "year: 2016 month 8\n",
      "year: 2016 month 9\n",
      "year: 2016 month 10\n",
      "year: 2016 month 11\n",
      "year: 2016 month 12\n"
     ]
    }
   ],
   "source": [
    "global_event_dict,region_event_dict,country_event_dict = cg.GetAllEventDictFromDf(year_df_dict,\n",
    "                                                                                  country_region_dict,\n",
    "                                                                                 country_predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(cg)\n",
    "# indexing dicts\n",
    "# for each level of abstraction {global,region,country}, get a set of actors, and then an index for them\n",
    "global_idx_dict,region_idx_dict,country_idx_dict = cg.GetAllIdxDict(global_event_dict,region_event_dict,country_event_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for region,agent_idx_dict in region_idx_dict.items():\n",
    "    print(region,len(agent_idx_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del year_df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# convert dicts to mats\n",
    "importlib.reload(cg)\n",
    "\n",
    "#adjmatgraph_global_dict = cg.GetAdjMatGraphDict(global_event_dict,global_idx_dict,num_time_steps)\n",
    "adjmatgraph_region_dict = cg.GetAdjMatGraphDict(region_event_dict,region_idx_dict,num_time_steps)\n",
    "#adjmatgraph_country_dict = cg.GetAdjMatGraphDict(country_event_dict,country_idx_dict,num_time_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tabular, aggreagate data\n",
    "importlib.reload(cne)\n",
    "cne.GenerateNodeAggregateEmbeddings(year_range,\n",
    "                                    indicator_year_month_dict,\n",
    "                                    country_predict_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lse = set()\n",
    "for year, year_data in adjmatgraph_country_dict.items():\n",
    "    for month, month_data in year_data.items():\n",
    "        if year==2014 and month==3:\n",
    "            break\n",
    "        for country in country_predict_list:\n",
    "            if country not in month_data.keys():\n",
    "                lse.add(country)        \n",
    "for country in lse:\n",
    "    country_predict_list.remove(country)\n",
    "    chaos_dict.pop(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#country_predict_list.pop(country_predict_list.index('Burkina Faso'))\n",
    "print(country_predict_list,lse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'CreateNodeEmbeddings' from '/Volumes/Big Vol/ICEWS/Jupyter-ICEWS/CreateNodeEmbeddings.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get node embeddings for factions\n",
    "importlib.reload(cne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cne.GenerateEmbeddings(adjmatgraph_global_dict,\n",
    "                       global_idx_dict,\n",
    "                       \"Global\",\n",
    "                       country_predict_list,\n",
    "                       nmc_dict,\n",
    "                      num_time_steps,\n",
    "                      year_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "cne.GenerateEmbeddings(adjmatgraph_region_dict,\n",
    "                       region_idx_dict,\n",
    "                       \"Region\",\n",
    "                       country_predict_list,\n",
    "                       nmc_dict,\n",
    "                      num_time_steps,\n",
    "                      year_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "importlib.reload(cne)\n",
    "cne.GenerateEmbeddings(adjmatgraph_country_dict,\n",
    "                       country_idx_dict,\n",
    "                       \"Country\",\n",
    "                       country_predict_list,\n",
    "                       nmc_dict,\n",
    "                       num_time_steps,\n",
    "                      year_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "region_agent_idx_dict = {region:idx for idx,region in enumerate(region_idx_dict.keys())}\n",
    "\n",
    "#region_embed_ndarr = cf.GetEmbedNDArr(\"RegionGraphData\",(158,7,1,6),region_agent_idx_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# maps country to region to region idx\n",
    "country_region_idx_dict = {country:region_agent_idx_dict[country_region_dict[country]] for country in country_predict_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TrainTest' from '/Volumes/Big Vol/ICEWS/Jupyter-ICEWS/TrainTest.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cf)\n",
    "importlib.reload(cne)\n",
    "importlib.reload(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up Country-Level Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "w=36\n",
    "T=48\n",
    "aug_T=12\n",
    "offset=0\n",
    "\n",
    "#country_predict_list = [country for country in os.listdir(\"CountryGraphData\")]\n",
    "#country_predict_list.remove('.ipynb_checkpoints')\n",
    "#country_predict_list.sort()\n",
    "\n",
    "active_countries = country_predict_list\n",
    "active_regions = list(region_idx_dict.keys())\n",
    "country_agent_idx_dict = {country:idx for idx,country in enumerate(active_countries)}\n",
    "region_agent_idx_dict = {region:idx for idx,region in enumerate(active_regions)}\n",
    "global_agent_idx_dict = {'global':0}\n",
    "country_global_dict = {country:\"global\" for country in country_predict_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 162, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_node_embed_ndarr = cf.GetNodeEmbedNDArr(\"GlobalNodeData\",(num_time_steps,len(active_countries),1),\n",
    "                                             global_agent_idx_dict,\n",
    "                                             global_idx_dict,\n",
    "                                        country_agent_idx_dict,\n",
    "                                               country_global_dict,\n",
    "                                             country_predict_list)\n",
    "global_node_embed_ndarr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 162, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_graph_embed_ndarr = cf.GetGraphEmbedNDArr(\"GlobalGraphData\",(num_time_steps,len(active_countries),1),\n",
    "                                             global_agent_idx_dict,\n",
    "                                             global_idx_dict,\n",
    "                                        country_agent_idx_dict,\n",
    "                                                 country_global_dict,\n",
    "                                             country_predict_list)\n",
    "global_graph_embed_ndarr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 162, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_node_embed_ndarr = cf.GetNodeEmbedNDArr(\"RegionNodeData\",(num_time_steps,len(active_countries),1),\n",
    "                                             region_agent_idx_dict,\n",
    "                                             region_idx_dict,\n",
    "                                        country_agent_idx_dict,\n",
    "                                               country_region_dict,\n",
    "                                             country_predict_list)\n",
    "region_node_embed_ndarr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 162, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_graph_embed_ndarr = cf.GetGraphEmbedNDArr(\"RegionGraphData\",(num_time_steps,len(active_countries),1),\n",
    "                                             region_agent_idx_dict,\n",
    "                                             region_idx_dict,\n",
    "                                        country_agent_idx_dict,\n",
    "                                                 country_region_dict,\n",
    "                                             country_predict_list)\n",
    "region_graph_embed_ndarr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 162, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_graph_embed_ndarr = cf.GetCountryGraphEmbedNDArr(\"CountryGraphData\",\n",
    "                                            (num_time_steps,len(active_countries),13),\n",
    "                                            country_agent_idx_dict,\n",
    "                                            country_predict_list)\n",
    "country_graph_embed_ndarr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Region-level Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "w=36\n",
    "T=48\n",
    "aug_T=12\n",
    "offset=0\n",
    "\n",
    "#country_predict_list = [country for country in os.listdir(\"CountryGraphData\")]\n",
    "#country_predict_list.remove('.ipynb_checkpoints')\n",
    "#country_predict_list.sort()\n",
    "\n",
    "region_predict_list = [region for region in region_idx_dict.keys()]\n",
    "active_regions = list(region_idx_dict.keys())\n",
    "region_agent_idx_dict = {region:idx for idx,region in enumerate(active_regions)}\n",
    "global_agent_idx_dict = {'global':0}\n",
    "region_region_dict = {region:region for region in active_regions}\n",
    "region_idx_dict = {region:{region:0} for region in active_regions}\n",
    "region_global_dict = {region:\"global\" for region in region_predict_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "region_graph_embed_ndarr = cf.GetGraphEmbedNDArr(\"RegionGraphData\",(num_time_steps,7,13),\n",
    "                                             region_agent_idx_dict,\n",
    "                                             region_idx_dict,\n",
    "                                        region_agent_idx_dict,\n",
    "                                            region_region_dict,\n",
    "                                             region_predict_list)\n",
    "region_graph_embed_ndarr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Big Vol/ICEWS/Jupyter-ICEWS/CreateFeatures.py:299: RuntimeWarning: invalid value encountered in true_divide\n",
      "  lV = lV / lV.sum()\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(cf)\n",
    "\n",
    "# \n",
    "dict_ndarr_triple_list = [\n",
    "                        (country_agent_idx_dict,country_graph_embed_ndarr,'country')\n",
    "    (country_agent_idx_dict,region_node_embed_ndarr,'region'),\n",
    "    (country_agent_idx_dict,region_graph_embed_ndarr,'region'),\n",
    "    (country_agent_idx_dict,global_node_embed_ndarr,'global'),\n",
    "    (country_agent_idx_dict,global_graph_embed_ndarr,'global')\n",
    "]\n",
    "agent_X_dict = cf.GenerateFeatures(dict_ndarr_triple_list,w,num_time_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TrainTest' from '/Volumes/Big Vol/ICEWS/Jupyter-ICEWS/TrainTest.py'>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(tt)\n",
    "\n",
    "T=48\n",
    "test_type=\"all_trim_Bag_100_global_region\" #S_all_BagRandom\" #_aug_best_S\" #graphs accumulated from the gross, not scaled graphs\n",
    "print(test_type)\n",
    "\n",
    "tt.TestClassLabels(agent_X_dict,country_class_labels_dict,T,w,offset,aug_T,country_region_dict,test_type) # flat_d or inf_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13, 6, 13, 6, 13\n",
    "# Country Graph S:  0:13\n",
    "# Region Node S:    13:19\n",
    "# Region Graph S:   19:31\n",
    "# Global Node S:    31:37\n",
    "# Global Graph S:   37:50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
